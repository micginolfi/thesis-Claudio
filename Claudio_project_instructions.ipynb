{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importa le librerie necessarie\n"
      ],
      "metadata": {
        "id": "nnZ-NtmhObpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Impostazione dei semi casuali per riproducibilità\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "GTxYQlc8pJqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design, training e validazione di un classificatore per MNIST\n",
        "\n",
        "questo classificatore (che può essere simile o uguale) a quello che hai già allenato per la prima parte della tesi, dovrà essere addestrato in questa fase e poi dovrà andare a valutare le cifre generate dal generatore della GAN nella seconda fase.\n"
      ],
      "metadata": {
        "id": "QkiSTE9qOt0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funzione per costruire il classificatore MNIST\n",
        "\n",
        "def build_classifier():\n",
        "    model = keras.Sequential([\n",
        "\n",
        "    # istruzione: riempi con architettura\n",
        "\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ZtvEmlSHpJsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica e prepara i dati MNIST\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalizza i dati come nel codice originale\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "x_test = (x_test.astype(np.float32) - 127.5) / 127.5\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)"
      ],
      "metadata": {
        "id": "8nSzCtTtpJvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea e addestra il classificatore\n",
        "MNIST_classifier = build_classifier()\n",
        "\n",
        "history = MNIST_classifier.fit(x_train, y_train, epochs=10, validation_split=0.2, verbose=1, batch_size=256)"
      ],
      "metadata": {
        "id": "dguLV6-opiUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizza l'andamento dell'addestramento\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Valuta il classificatore sul set di test\n",
        "test_loss, test_acc = MNIST_classifier.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "nY79D3C4pJyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea la matrice di confusione\n",
        "y_pred = MNIST_classifier.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "# Visualizza la matrice di confusione\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.ylabel('True Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1ImMYaGpJ2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizza alcuni esempi con le probabilità predette\n",
        "\n",
        "num_examples = 10\n",
        "random_indices = np.random.choice(len(x_test), num_examples, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 3*num_examples))\n",
        "for i, idx in enumerate(random_indices):\n",
        "    plt.subplot(num_examples, 2, 2*i+1)\n",
        "    plt.imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"True Label: {y_test[idx]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(num_examples, 2, 2*i+2)\n",
        "    probs = MNIST_classifier.predict(x_test[idx].reshape(1, 28, 28, 1))[0]\n",
        "    plt.bar(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], probs)\n",
        "    plt.title(f\"Predicted Probabilities\")\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ap2K3jrNpJ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design e training di una GAN per generare immagini di numeri 1, 2 e 3 simili a MNIST\n",
        "\n",
        "Per semplificare la task andremo a generare solo numeri 1, 2 e 3.\n"
      ],
      "metadata": {
        "id": "LYaFYwJIpp23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impostazione parametri globali\n",
        "\n",
        "LATENT_DIM = 100 # Dimensione del vettore di rumore latente da usare come input al generatore\n",
        "NUM_EPOCHS = 100 # Numero di epoche di allenamento del GAN\n",
        "BATCH_SIZE = 64 # Dimensione del batch per l'allenamento\n",
        "NUM_SAMPLES = 5000 # Numero di esempi da selezionare casualmente dal dataset MNIST (evitiamo di usare l'intero dataset per risparmiare tempo)"
      ],
      "metadata": {
        "id": "I1mM8Hphpth1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Funzioni di utilità per la preparazione dei dati e la visualizzazione\n",
        "\n",
        "def carica_e_prepara_dati():\n",
        "    \"\"\"\n",
        "    Carica il dataset MNIST, seleziona solo le cifre 1, 2 e 3,\n",
        "    normalizza le immagini e seleziona un sottoinsieme casuale.\n",
        "    \"\"\"\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Seleziona solo le cifre 1, 2 e 3\n",
        "    mask = np.isin(y_train, [1, 2, 3])\n",
        "    x_train, y_train = x_train[mask], y_train[mask]\n",
        "\n",
        "    # Normalizza le immagini nell'intervallo [-1, 1]\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "    # Seleziona un sottoinsieme casuale di esempi\n",
        "    indici_casuali = np.random.choice(x_train.shape[0], NUM_SAMPLES, replace=False)\n",
        "    x_train, y_train = x_train[indici_casuali], y_train[indici_casuali]\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "def visualizza_esempi(x_train, num_esempi=10):\n",
        "    \"\"\"\n",
        "    Visualizza un numero specificato di esempi casuali dal dataset.\n",
        "    \"\"\"\n",
        "    num_righe = int(np.sqrt(num_esempi))\n",
        "    num_colonne = int(np.ceil(num_esempi / num_righe))\n",
        "\n",
        "    plt.figure(figsize=(num_colonne, num_righe))\n",
        "    for i in range(num_esempi):\n",
        "        plt.subplot(num_righe, num_colonne, i+1)\n",
        "        plt.imshow(x_train[np.random.randint(0, x_train.shape[0])].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Carica e prepara i dati\n",
        "x_train, y_train = carica_e_prepara_dati()\n",
        "\n",
        "print(\"Dimensioni del dataset di allenamento:\", x_train.shape)\n",
        "\n",
        "visualizza_esempi(x_train, num_esempi=100)"
      ],
      "metadata": {
        "id": "EVPUn6m4ptkm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # definizione del generatore e il discriminatore del GAN e le funzioni di perdita\n",
        "\n",
        "def crea_generatore():\n",
        "    \"\"\"\n",
        "    Crea e restituisce il modello del generatore.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "\n",
        "    # istruzione: progettare architettura per il generatore\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def crea_discriminatore():\n",
        "    \"\"\"\n",
        "    Crea e restituisce il modello del discriminatore.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "\n",
        "        # istruzione: progettare architettura per il discriminatore\n",
        "        # l'ultimo strato sarà un layer denso con un valore in output, che verrà successivamente\n",
        "        # interpretato come probabilità di essere una sorgente reale o fake\n",
        "\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def loss_discriminatore(output_reale, output_falso):\n",
        "    \"\"\"\n",
        "    Calcola la loss del discriminatore.\n",
        "    Quanto bene il discriminatore riesce a distinguere le immagini reali da quelle generate?\n",
        "    Questa loss cerca di massimizzare la probabilità di classificare correttamente sia le immagini reali che quelle generate.\n",
        "    In altre parole, cerca di minimizzare la probabilità che il discriminatore classifichi le immagini reali come false e le immagini generate come vere.\n",
        "    \"\"\"\n",
        "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    loss_reale = cross_entropy(tf.ones_like(output_reale), output_reale)\n",
        "    loss_falso = cross_entropy(tf.zeros_like(output_falso), output_falso)\n",
        "    return loss_reale + loss_falso\n",
        "\n",
        "def loss_generatore(output_falso):\n",
        "    \"\"\"\n",
        "    Calcola la loss del generatore.\n",
        "    Quanto bene il generatore riesce a ingannare il discriminatore?\n",
        "    Questa loss cerca di minimizzare la probabilità che il discriminatore classifichi correttamente le immagini generate come false.\n",
        "    In altre parole, cerca di massimizzare la probabilità che il discriminatore classifichi le immagini generate come vere.\n",
        "    \"\"\"\n",
        "    cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return cross_entropy(tf.ones_like(output_falso), output_falso)\n",
        "\n",
        "\n",
        "# Creazione dei modelli e visualizzazione dettagli tramite la funzione .summary() di Keras\n",
        "generatore = crea_generatore()\n",
        "generatore.summary()\n",
        "discriminatore = crea_discriminatore()\n",
        "discriminatore.summary()\n"
      ],
      "metadata": {
        "id": "midxAEEAptnQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function # Questo comando vuol dire che la funzione verrà eseguita in modalità grafica per prestazioni migliori durante l'allenamento del GAN (una peculiarità di TensorFlow)\n",
        "def step_allenamento(immagini, generatore, discriminatore, ottimizzatore_gen, ottimizzatore_disc):\n",
        "    \"\"\"\n",
        "    Esegue un singolo step di allenamento per il GAN.\n",
        "    Questa funzione alterna l'ottimizzazione del generatore e del discriminatore, calcolando le relative loss.\n",
        "    L'allenamento del generatore cerca di massimizzare la probabilità che il discriminatore classifichi le immagini generate come vere.\n",
        "    L'allenamento del discriminatore cerca di massimizzare la probabilità di classificare correttamente sia le immagini reali che quelle generate.\n",
        "    \"\"\"\n",
        "    rumore = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        immagini_generate = generatore(rumore, training=True)\n",
        "\n",
        "        output_reale = discriminatore(immagini, training=True)\n",
        "        output_falso = discriminatore(immagini_generate, training=True)\n",
        "\n",
        "        loss_gen = loss_generatore(output_falso)\n",
        "        loss_disc = loss_discriminatore(output_reale, output_falso)\n",
        "\n",
        "    gradienti_generatore = gen_tape.gradient(loss_gen, generatore.trainable_variables)\n",
        "    gradienti_discriminatore = disc_tape.gradient(loss_disc, discriminatore.trainable_variables)\n",
        "\n",
        "    ottimizzatore_gen.apply_gradients(zip(gradienti_generatore, generatore.trainable_variables))\n",
        "    ottimizzatore_disc.apply_gradients(zip(gradienti_discriminatore, discriminatore.trainable_variables))\n",
        "\n",
        "    return loss_gen, loss_disc\n",
        "\n",
        "def salva_immagini_generate(immagini, epoca, cartella='immagini_generate'):\n",
        "    \"\"\"\n",
        "    Salva le immagini generate in una griglia.\n",
        "    Questo serve per visualizzare come cambiano le immagini generate durante l'allenamento.\n",
        "    Se le immagini vengono generate a partire dallo stesso rumore, dovrebbe vedersi un progressivo miglioramento nella qualità delle immagini durante l'allenamento.\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for img, ax in zip(immagini, axs):\n",
        "        ax.imshow((img.numpy() * 127.5 + 127.5).astype(np.uint8), cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "    if not os.path.exists(cartella):\n",
        "        os.makedirs(cartella)\n",
        "\n",
        "    plt.savefig(f\"{cartella}/epoca_{epoca+1:03d}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def valuta_frazione_immagini_confidenti(generatore, classificatore, confidenza = 0.95, num_immagini=100):\n",
        "    \"\"\"\n",
        "    Valuta la frazione di immagini generate classificate come 1, 2, o 3 con alta confidenza.\n",
        "    Serve a valutare quanto bene il generatore è in grado di generare immagini simili a quelle del dataset.\n",
        "    In questo modo possiamo vedere se il generatore è in grado di generare immagini simili a quelle del dataset di allenamento.\n",
        "    Si potrebbe fare visulmente, ma questa funzione fornisce una misura quantitativa.\n",
        "    Fatto questo, useremo anche LLMs con visione per valutare la qualità delle immagini generate in modo indipendente.\n",
        "    \"\"\"\n",
        "\n",
        "    # istruzione: riempi questa funzione con del codice che genera un numero num_immagini di immagini\n",
        "    # usando il generatore, e le passa in input per la classificazione al classificatore MNIST_classifier.\n",
        "    # Bisogna poi calcolare la frazione di queste immagini per cui il MNIST_classifier pensa che l'immagine sia\n",
        "    # un 1, o un 2 o un 3, con una probabilità piu grande della variabile \"confidenza\".\n",
        "\n",
        "    return conteggio_confidenti\n"
      ],
      "metadata": {
        "id": "orSxZuCqptp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salva_immagini_random_generate(generatore, num_esempi=100, epoca=0, latent_dim=32):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di immagini generate.\n",
        "    \"\"\"\n",
        "    rumore = tf.random.normal([num_esempi, latent_dim])\n",
        "    immagini_generate = generatore(rumore, training=False).numpy()\n",
        "\n",
        "    num_righe = int(np.sqrt(num_esempi))\n",
        "    num_colonne = int(np.ceil(num_esempi / num_righe))\n",
        "\n",
        "    plt.figure(figsize=(num_colonne, num_righe))\n",
        "    for i in range(num_esempi):\n",
        "        plt.subplot(num_righe, num_colonne, i+1)\n",
        "        plt.imshow(immagini_generate[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"immagini_casuali/epoca_{epoca+1:03d}.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "def allena_gan(generatore, discriminatore, dataset, classificatore):\n",
        "    \"\"\"\n",
        "    Allena il GAN e restituisce le metriche di allenamento.\n",
        "    \"\"\"\n",
        "\n",
        "    # Learning rate per gli ottimizzatori del generatore e del discriminatore (come nell'articolo originale di DCGAN)\n",
        "    ottimizzatore_gen = keras.optimizers.Adam(1e-4)\n",
        "    ottimizzatore_disc = keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    # definire le liste per memorizzare le loss e la frazione di immagini confidenti\n",
        "    losses_gen, losses_disc = [], []\n",
        "    conteggio_immagini_confidenti = []\n",
        "\n",
        "    # Genera rumore fisso per visualizzare le immagini generate durante l'allenamento\n",
        "    # Lo facciamo per 64 immagini\n",
        "    rumore_fisso = tf.random.normal([64, LATENT_DIM])\n",
        "\n",
        "    # comincia l'allenamento, ciclo sul numero di epoche\n",
        "    for epoca in range(NUM_EPOCHS):\n",
        "\n",
        "        losses_gen_batch, losses_disc_batch = [], []\n",
        "\n",
        "        # ciclo sul dataset in batch all'interno di ogni epoca\n",
        "        for batch in dataset:\n",
        "            loss_gen, loss_disc = step_allenamento(batch, generatore, discriminatore,\n",
        "                                                   ottimizzatore_gen, ottimizzatore_disc)\n",
        "            losses_gen_batch.append(loss_gen)\n",
        "            losses_disc_batch.append(loss_disc)\n",
        "\n",
        "        # salviamo le loss medie per epoca, mediando su tutti i batch\n",
        "        losses_gen.append(np.mean(losses_gen_batch))\n",
        "        losses_disc.append(np.mean(losses_disc_batch))\n",
        "\n",
        "        # Genera e salva immagini usando rumore fisso\n",
        "        immagini_generate = generatore(rumore_fisso, training=False)\n",
        "        salva_immagini_generate(immagini_generate, epoca)\n",
        "\n",
        "        # Valuta la frazione di immagini confidenti\n",
        "        conteggio_confidenti = valuta_frazione_immagini_confidenti(generatore, classificatore)\n",
        "        conteggio_immagini_confidenti.append(conteggio_confidenti)\n",
        "\n",
        "        salva_immagini_random_generate(generatore, num_esempi=100, epoca=epoca, latent_dim=LATENT_DIM)\n",
        "\n",
        "        print(f\"Epoca {epoca+1}/{NUM_EPOCHS}, Loss_Gen: {losses_gen[-1]:.4f}, \"\n",
        "              f\"Loss_Disc: {losses_disc[-1]:.4f}, Immagini confidenti: {conteggio_confidenti:.2f}\")\n",
        "\n",
        "    return losses_gen, losses_disc, conteggio_immagini_confidenti\n",
        "\n",
        "\n",
        "# Crea il dataset in formato TensorFlow, diviso in batch e shufflato casualmente\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(x_train.shape[0]).batch(BATCH_SIZE)\n",
        "\n",
        "# Allena il GAN e salva le metriche di allenamento e la frazione di immagini confidenti per ogni epoca, da visualizzare successivamente\n",
        "losses_gen, losses_disc, conteggio_immagini_confidenti = allena_gan(generatore, discriminatore, dataset, classificatore= MNIST_classifier)\n"
      ],
      "metadata": {
        "id": "1gXTqZSnptsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizza_metriche(losses_gen, losses_disc, conteggio_immagini_confidenti):\n",
        "    \"\"\"\n",
        "    Visualizza le metriche di allenamento del GAN.\n",
        "    \"\"\"\n",
        "    epoche = np.arange(1, len(losses_gen)+1)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    ax1.plot(epoche, losses_gen, label='Loss Generatore', color='blue')\n",
        "    ax1.plot(epoche, losses_disc, label='Loss Discriminatore', color='red')\n",
        "    ax1.set_xlabel('Epoche')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Loss del Generatore e del Discriminatore')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(epoche, conteggio_immagini_confidenti, label='Immagini confidenti', color='green')\n",
        "    ax2.set_xlabel('Epoche')\n",
        "    ax2.set_ylabel('Frazione')\n",
        "    ax2.set_title('Frazione di Immagini Confidenti')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizza le metriche di allenamento\n",
        "visualizza_metriche(losses_gen, losses_disc, conteggio_immagini_confidenti)"
      ],
      "metadata": {
        "id": "gi34t9CaptvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizza degli esempi di immagini generate durante l'allenamento con le relative probabilità predette dal classificatore pre-addestrato\n",
        "\n",
        "def visualizza_immagini_generate_con_probabilita(generatore, classificatore, num_esempi=20):\n",
        "    \"\"\"\n",
        "    Visualizza esempi di immagini generate con le relative probabilità predette.\n",
        "    \"\"\"\n",
        "    rumore = tf.random.normal([num_esempi, LATENT_DIM])\n",
        "    immagini_generate = generatore(rumore, training=False).numpy()\n",
        "\n",
        "    plt.figure(figsize=(15, 3*num_esempi))\n",
        "    for i in range(num_esempi):\n",
        "        plt.subplot(num_esempi, 2, 2*i+1)\n",
        "        plt.imshow(immagini_generate[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_esempi, 2, 2*i+2)\n",
        "        probs = classificatore.predict(immagini_generate[i].reshape(1, 28, 28, 1))[0]\n",
        "        plt.bar(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], probs)\n",
        "        plt.title(\"Probabilità Predette\")\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualizza esempi di immagini generate\n",
        "visualizza_immagini_generate_con_probabilita(generatore, classificatore = MNIST_classifier)"
      ],
      "metadata": {
        "id": "02kvvqRfptyO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}